{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyecharts in c:\\users\\marija\\anaconda3\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: simplejson in c:\\users\\marija\\anaconda3\\lib\\site-packages (from pyecharts) (3.17.2)\n",
      "Requirement already satisfied: prettytable in c:\\users\\marija\\anaconda3\\lib\\site-packages (from pyecharts) (2.1.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\marija\\anaconda3\\lib\\site-packages (from pyecharts) (2.10)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\marija\\anaconda3\\lib\\site-packages (from prettytable->pyecharts) (0.1.7)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\marija\\anaconda3\\lib\\site-packages (from prettytable->pyecharts) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\marija\\anaconda3\\lib\\site-packages (from jinja2->pyecharts) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in c:\\users\\marija\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->prettytable->pyecharts) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\marija\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->prettytable->pyecharts) (3.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\marija\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#link\n",
    "#https://github.com/jxzly/Biomedical-Relation-Classification/tree/b74ce58a6a47af2cffdcaea2949ad359bf75b07b\n",
    "!pip install pyecharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Graph\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,TensorDataset,DataLoader\n",
    "from keras.preprocessing import sequence\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,TensorDataset,DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Conf:\n",
    "    # some information can be found in:\n",
    "    # Percha B, Altman R B. A global network of biomedical relationships derived from text[J]. Bioinformatics, 2018, 34(15): 2614-2624.\n",
    "    download_url = {'chemical-disease':['https://zenodo.org/record/1035500/files/part-i-chemical-disease-path-theme-distributions.txt?download=1',\n",
    "                                             'https://zenodo.org/record/1035500/files/part-ii-dependency-paths-chemical-disease-sorted-with-themes.txt?download=1'],\n",
    "                    'chemical-gene':['https://zenodo.org/record/1035500/files/part-i-chemical-gene-path-theme-distributions.txt?download=1',\n",
    "                                                               'https://zenodo.org/record/1035500/files/part-ii-dependency-paths-chemical-gene-sorted-with-themes.txt?download=1'],\n",
    "                    'gene-disease':['https://zenodo.org/record/1035500/files/part-i-gene-disease-path-theme-distributions.txt?download=1',\n",
    "                                             'https://zenodo.org/record/1035500/files/part-ii-dependency-paths-gene-disease-sorted-with-themes.txt?download=1'],\n",
    "                    }\n",
    "    usecols = {'chemical-disease':['path', 'T', 'C', 'Sa', 'Pr', 'Pa', 'J', 'Mp'],\n",
    "               'chemical-gene':['path', 'A+', 'A-', 'B', 'E+', 'E-', 'E', 'N', 'O', 'K', 'Z'],\n",
    "               'gene-disease':['path', 'U', 'Ud', 'D', 'J', 'Te', 'Y', 'G', 'Md', 'X', 'L'],\n",
    "               'gene-gene':['path', 'B', 'W', 'V+', 'E+', 'E', 'I', 'H', 'Rg', 'Q'],\n",
    "               }\n",
    "    relation_type = {'chemical-disease':['T', 'C', 'Sa', 'Pr', 'Pa', 'J'],\n",
    "                     'disease-chemical':['Mp'],\n",
    "                     'chemical-gene':['A+', 'A-', 'B', 'E+', 'E-', 'E', 'N'],\n",
    "                     'gene-chemical':['O', 'K', 'Z'],\n",
    "                     'gene-disease':['U', 'Ud', 'D', 'J', 'Te', 'Y', 'G'],\n",
    "                     'disease-gene':['Md', 'X', 'L'],\n",
    "                     'gene-gene':['B', 'W', 'V+', 'E+', 'E', 'I', 'H', 'Rg', 'Q']\n",
    "                     }\n",
    "    relation_theme = {'chemical-disease':{'T':'Treatment/therapy (incl. investigatory)',\n",
    "                                          'C':'Inhibits cell growth (esp. cancers)',\n",
    "                                          'Sa':'Side effect/adverse event',\n",
    "                                          'Pr':'Prevents, suppresses',\n",
    "                                          'Pa':'Alleviates, reduces',\n",
    "                                          'J':'Role in pathogenesis',\n",
    "                                          },\n",
    "                      'disease-chemical':{'Mp':'Biomarkers (progression)',\n",
    "                                          },\n",
    "                      'chemical-gene':{'A+':'Agonism, activation',\n",
    "                                       'A-':'Antagonism, blocking',\n",
    "                                       'B':'Binding, ligand (esp. receptors)',\n",
    "                                       'E+':'Increases expression/production',\n",
    "                                       'E-':'Decreases expression/production',\n",
    "                                       'E':'Affects expression/production (neutral)',\n",
    "                                       'N':'Inhibits',\n",
    "                                       },\n",
    "                      'gene-chemical':{'O':'Transport, channels',\n",
    "                                       'K':'Metabolism, pharmacokinetics',\n",
    "                                       'Z':'Enzyme activity',\n",
    "                                       },\n",
    "                      'gene-disease':{'U':'Causal mutations',\n",
    "                                      'Ud':'Mutations affect disease course',\n",
    "                                      'D':'Drug targets',\n",
    "                                      'J':'Role in pathogenesis',\n",
    "                                      'Te':'Possible therapeutic effect',\n",
    "                                      'Y':'Polymorphisms alter risk',\n",
    "                                      'G':'Promotes progression',\n",
    "                                      },\n",
    "                      'disease-gene':{'Md':'Biomarkers (diagnostic)',\n",
    "                                      'X':'Overexpression in disease',\n",
    "                                      'L':'Improper regulation linked to disease',\n",
    "                                      },\n",
    "                      'gene-gene':{'B':'Binding, ligand (esp. receptors)',\n",
    "                                   'W':'Enhances response',\n",
    "                                   'V+':'Activates, stimulates',\n",
    "                                   'E+':'Increases expression/production',\n",
    "                                   'E':'Affects expression/production (neutral)',\n",
    "                                   'I':'Signaling pathway',\n",
    "                                   'H':'Same protein or complex',\n",
    "                                   'Rg':'Regulation',\n",
    "                                   'Q':'Production by cell population',\n",
    "                                   }\n",
    "                       }\n",
    "    confidence_limit = {'chemical-disease':0.9,\n",
    "                        'chemical-gene':0.5,\n",
    "                        'gene-disease':0.6,\n",
    "                        'gene-gene':0.9,\n",
    "                        }\n",
    "\n",
    "def Data_loader(x,y=None,bs=128,shuffle=False,numWorkers=0):\n",
    "    if y is not None:\n",
    "        data = TensorDataset(x,y)\n",
    "    else:\n",
    "        data = TensorDataset(x)\n",
    "    data_loader = DataLoader(dataset=data,batch_size=bs,shuffle=shuffle,num_workers=numWorkers)\n",
    "    return data_loader\n",
    "\n",
    "def Bert_conf(tokenizer=None,model=None):\n",
    "    # add some tokens to vocab\n",
    "    if tokenizer != None:\n",
    "        num_added_toks = tokenizer.add_tokens(['start_entity', 'end_entity'])\n",
    "        print('We have added', num_added_toks, 'tokens')\n",
    "    if model != None:\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def Bert_model(taskType,bertPath):\n",
    "    label_df = pd.read_csv('D:\\\\IJS_MASTER\\\\SemanticWebTechnologies\\\\Covid19_Dataset\\\\%s_label.csv'%taskType)\n",
    "    tokenizer = BertTokenizer.from_pretrained(bertPath,do_lower_case=False)\n",
    "    model = BertForSequenceClassification.from_pretrained(bertPath, num_labels=label_df['label'].nunique())\n",
    "    Bert_conf(tokenizer,model)\n",
    "    return tokenizer,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys,os,re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class Prepare_Data(Conf):\n",
    "    def __init__(self,taskType,confidenceLimit,predictionPath,maxSeqLen,bertPath):\n",
    "        super(Prepare_Data,self).__init__()\n",
    "        self.task_type = taskType\n",
    "        self.confidence_limit = confidenceLimit\n",
    "        self.prediction_path = predictionPath\n",
    "        self.max_seq_len = maxSeqLen\n",
    "        self.bert_path = bertPath\n",
    "\n",
    "    def Prepare_train_test_data(self,tokenizer,trainBS,evalBS):\n",
    "        # if not exist original data, download them\n",
    "    \n",
    "\n",
    "        # build data loder\n",
    "        path_theme_df = pd.read_csv('D:\\\\IJS_MASTER\\\\SemanticWebTechnologies\\\\Covid19_Dataset\\\\data\\\\part-i-%s-path-theme-distributions.txt'%self.task_type,sep='\\t',\n",
    "                                    usecols=self.usecols[self.task_type])\n",
    "        path_theme_df['max_value_prob'] = path_theme_df[self.usecols[self.task_type][1:]].max(axis=1) / path_theme_df[self.usecols[self.task_type][1:]].sum(axis=1)\n",
    "        path_theme_df = path_theme_df.loc[path_theme_df['max_value_prob']>self.confidence_limit].reset_index(drop=True)\n",
    "        path_theme_df['label_raw'] = path_theme_df[self.usecols[self.task_type][1:]].apply(lambda x:x.argmax(),axis=1)\n",
    "        path_theme_df.drop(self.usecols[self.task_type][1:],axis=1,inplace=True)\n",
    "        sentence_df = pd.read_csv('D:\\\\IJS_MASTER\\\\SemanticWebTechnologies\\\\Covid19_Dataset\\\\data\\\\part-ii-dependency-paths-%s-sorted-with-themes.txt'%self.task_type,sep='\\t',header=None,\n",
    "                                  names=['PubMed_ID','sentence_number','start_entity','start_entity_location','end_entity','end_entity_location','start_entity_raw','end_entity_raw','start_entity_database_id','end_entity_database_id','start_entity_type','end_entity_type','path','sentence_tokenized'],\n",
    "                                  usecols=['start_entity','end_entity','path','sentence_tokenized'],nrows=None)\n",
    "        sentence_df = sentence_df.loc[~((sentence_df['start_entity'].isna())|(sentence_df['end_entity'].isna()))].reset_index(drop=True)\n",
    "        sentence_df['path'] = sentence_df['path'].apply(lambda x:x.lower())\n",
    "        sentence_df['sentence_tokenized'] = sentence_df.apply(lambda x:x['sentence_tokenized'].replace(x['start_entity'],'start_entity').replace(x['end_entity'],'end_entity'),axis=1)\n",
    "        sentence_df = sentence_df.merge(path_theme_df[['path','label_raw']],how='inner',on='path')\n",
    "\n",
    "        # encoder labels\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(sentence_df['label_raw'].values.tolist())\n",
    "        label_df = pd.DataFrame({'label_raw':le.classes_,'label':list(range(len(le.classes_)))})\n",
    "        # map label to theme\n",
    "        theme_dic = self.relation_theme[self.task_type]\n",
    "        if self.task_type.split('-')[0] != self.task_type.split('-')[1]:\n",
    "            theme_dic.update(self.relation_theme[self.task_type.split('-')[1]+'-'+self.task_type.split('-')[0]])\n",
    "        label_df['theme'] = label_df['label_raw'].map(theme_dic)\n",
    "        label_df.to_csv('D:\\\\IJS_MASTER\\\\SemanticWebTechnologies\\\\Covid19_Dataset\\\\data\\\\%s_label.csv'%self.task_type,index=False)\n",
    "        sentence_df['label'] = le.transform(sentence_df['label_raw'].values)\n",
    "\n",
    "        # covert sentences to ids in bert\n",
    "        ids = sentence_df['sentence_tokenized'].apply(lambda x:tokenizer.convert_tokens_to_ids(tokenizer.tokenize(x))).tolist()\n",
    "        ids = sequence.pad_sequences(ids,self.max_seq_len, truncating='post', padding='post')\n",
    "\n",
    "        # split data to train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(ids,sentence_df['label'].values, test_size=0.2, stratify=sentence_df['label'].values, random_state=2020)\n",
    "        train_data_loader = Data_loader(torch.LongTensor(X_train),torch.LongTensor(y_train),bs=trainBS)\n",
    "        test_data_loader = Data_loader(torch.LongTensor(X_test),torch.LongTensor(y_test),bs=evalBS)\n",
    "        return train_data_loader,test_data_loader\n",
    "\n",
    "    def Prepare_predict_data(self,tokenizer,bs):\n",
    "        #tuka proveri\n",
    "        marked_sentence_df = pd.read_csv('D:\\\\IJS_MASTER\\\\SemanticWebTechnologies\\\\Covid19_Dataset\\\\marked_sentence_2.csv')\n",
    "        marked_sentences = marked_sentence_df.loc[(marked_sentence_df['start_entity_type'].apply(lambda x:x.lower())==self.task_type.split('-')[0])&\\\n",
    "                                                  (marked_sentence_df['end_entity_type'].apply(lambda x:x.lower())==self.task_type.split('-')[1]),'marked_sentence']\n",
    "\n",
    "        ids = marked_sentences.apply(lambda x:tokenizer.convert_tokens_to_ids(tokenizer.tokenize(x))).tolist()\n",
    "        ids = sequence.pad_sequences(ids,self.max_seq_len, truncating='post', padding='post')\n",
    "        # we cannot confirm order of entities, so predict two possibilities\n",
    "        reverse_marked_sentences = marked_sentence_df.loc[(marked_sentence_df['start_entity_type'].apply(lambda x:x.lower())==self.task_type.split('-')[0])&\\\n",
    "                                                  (marked_sentence_df['end_entity_type'].apply(lambda x:x.lower())==self.task_type.split('-')[1]),'marked_sentence']\\\n",
    "                                                  .apply(lambda x:x.replace('start_entity','init_start_entity').replace('end_entity','start_entity').replace('init_start_entity','end_entity'))\n",
    "        reverse_ids = reverse_marked_sentences.apply(lambda x:tokenizer.convert_tokens_to_ids(tokenizer.tokenize(x))).tolist()\n",
    "        reverse_ids = sequence.pad_sequences(reverse_ids,self.max_seq_len, truncating='post', padding='post')\n",
    "        predict_data_loader = Data_loader(torch.LongTensor(ids),torch.LongTensor(reverse_ids),bs=bs)\n",
    "        return marked_sentences.values,predict_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer\n",
    "import argparse\n",
    "\n",
    "conf = Conf()\n",
    "\n",
    "def Parse_args():\n",
    "    args = argparse.ArgumentParser()\n",
    "    args.add_argument('--task_type',\n",
    "                      default='chemical-disease', help='task type:chemical-disease,chemical-gene,gene-disease')\n",
    "    args.add_argument('--confidence_limit', type=float,\n",
    "                      default=-1.0, help='dependency path lower confidence limit, use suggestion value if it equal -1.0. \\\n",
    "                      suggestion value:0.9 for chemical-disease; 0.5 for chemical-gene; 0.6 for gene-disease; 0.9 for gene-gene')\n",
    "    args.add_argument('--prediction_path',\n",
    "                      default='COVID-19', help='prediction data path')\n",
    "    args.add_argument('--max_seq_len', type=int,\n",
    "                      default=64, help='padding length of sequence')\n",
    "    args.add_argument('--bert_path',\n",
    "                      default='./pretrained/bert-base-cased', help='bert model path')\n",
    "    args.add_argument('--lr', type=float, default=1e-5)\n",
    "    args.add_argument('--train_bs', type=int, default=128, help='train batch size')\n",
    "    args.add_argument('--eval_bs', type=int, default=128, help='evaluate batch size')\n",
    "    args.add_argument('--epochs', type=int, default=100)\n",
    "    args.add_argument('--cuda', type=int, default=0, help='which gpu be used')\n",
    "    args = args.parse_args()\n",
    "    return args\n",
    "\n",
    "args = Parse_args()\n",
    "# dependency path lower confidence limit, use suggestion value if it equal -1.0\n",
    "confidence_limit = args.confidence_limit if args.confidence_limit != -1.0 else conf.confidence_limit[args.task_type]\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_path,do_lower_case=False)\n",
    "Bert_conf(tokenizer)\n",
    "prepare = Prepare_Data(args.task_type,confidence_limit,args.prediction_path,args.max_seq_len,args.bert_path)\n",
    "\n",
    "def Load_train_test_data():\n",
    "    train_data_loader,test_data_loader = prepare.Prepare_train_test_data(tokenizer,args.train_bs,args.eval_bs)\n",
    "    return train_data_loader,test_data_loader\n",
    "\n",
    "def Load_predict_data():\n",
    "    marked_sentences,predict_data_loader = prepare.Prepare_predict_data(tokenizer,args.eval_bs)\n",
    "    return marked_sentences,predict_data_loader\n",
    "\n",
    "train_data_loader,test_data_loader = Load_train_test_data()\n",
    "marked_sentences,predict_data_loader = Load_predict_data()\n",
    "device = torch.device('cuda:%s'%args.cuda if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "\n",
    "def Train(evalEpochs=None):\n",
    "    tokenizer,model = Bert_model(args.task_type,args.bert_path)\n",
    "    tokenizer.save_pretrained('D:\\\\IJS_MASTER\\\\SemanticWebTechnologies\\\\Biomedical-Relation-Classification-master\\\\model\\\\%s'%args.task_type)\n",
    "    model = model.to(device)\n",
    "    model_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(model_params, lr=args.lr)\n",
    "    for epoch in range(args.epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in tqdm(train_data_loader):\n",
    "            ids, labels = [t.to(device) for t in data]\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            outputs = model(input_ids=ids,labels=labels)\n",
    "            loss = outputs[0]\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'[epoch {epoch+1}] loss: {running_loss:3f}')\n",
    "        if evalEpochs != None:\n",
    "            if (epoch+1)%evalEpochs == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "                Evaluate(model)\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "    model_to_save.save_pretrained('D:\\\\IJS_MASTER\\\\SemanticWebTechnologies\\\\Biomedical-Relation-Classification-master\\\\model\\\\%s'%args.task_type)\n",
    "    torch.cuda.empty_cache()\n",
    "    return\n",
    "\n",
    "def Evaluate(model=None):\n",
    "    if model == None:\n",
    "        tokenizer,model = Bert_model(args.task_type,'D:\\\\IJS_MASTER\\\\SemanticWebTechnologies\\\\Biomedical-Relation-Classification-master\\\\model\\\\%s'%args.task_type)\n",
    "        model = model.to(device)\n",
    "    test_preds,test_labels = [],[]\n",
    "    for data in tqdm(test_data_loader):\n",
    "        ids, labels = [t.to(device) for t in data]\n",
    "        outputs = model(input_ids=ids)\n",
    "        logits = outputs[0]\n",
    "        _, pred = torch.max(logits.data, 1)\n",
    "        test_preds.extend(list(pred.cpu().detach().numpy()))\n",
    "        test_labels.extend(list(labels.cpu().detach().numpy()))\n",
    "    macro_f1 = f1_score(test_labels,test_preds,average='macro')\n",
    "    print('test macro f1 score:%.4f'%macro_f1)\n",
    "    torch.cuda.empty_cache()\n",
    "    return\n",
    "\n",
    "def Predict():\n",
    "    reverse_task_type = args.task_type.split('-')[1] + '-' + args.task_type.split('-')[0]\n",
    "    def Filter(x):\n",
    "        if x['init_pred'] in conf.relation_type[args.task_type]:\n",
    "            if x['reverse_pred'] not in conf.relation_type[reverse_task_type]:\n",
    "                # init_pred is a correct relation but reverse_pred not\n",
    "                return 'init_pred'\n",
    "            else:\n",
    "                # init_pred and reverse_pred both are correct relations\n",
    "                if x['init_pred_prob'] >= x['reverse_pred_prob']:\n",
    "                    # init_pred_prob greater than or equal to reverse_pred_prob\n",
    "                    return 'init_pred'\n",
    "                else:\n",
    "                    return 'reverse_pred'\n",
    "        else:\n",
    "            if x['reverse_pred'] not in conf.relation_type[reverse_task_type]:\n",
    "                # init_pred and reverse_pred both are uncorrect relations\n",
    "                return 'uncorrect'\n",
    "            else:\n",
    "                # reverse_pred is a correct relation but init_pred not\n",
    "                return 'reverse_pred'\n",
    "    marked_sentence_df = pd.read_csv('./data/%s/marked_sentence.csv'%args.prediction_path)\n",
    "    label_df = pd.read_csv('D:\\\\IJS_MASTER\\\\SemanticWebTechnologies\\\\Covid19_Dataset\\\\%s_label.csv'%args.task_type)\n",
    "    tokenizer,model = Bert_model(args.task_type,'D:\\\\IJS_MASTER\\\\SemanticWebTechnologies\\\\Biomedical-Relation-Classification-master\\\\model\\\\%s'%args.task_type)\n",
    "    model = model.to(device)\n",
    "    preds = []\n",
    "    preds_prob = []\n",
    "    reverse_preds = []\n",
    "    reverse_preds_prob = []\n",
    "    for data in tqdm(predict_data_loader):\n",
    "        ids,reverse_ids = [t.to(device) for t in data]\n",
    "        outputs = model(input_ids=ids)\n",
    "        logits = outputs[0]\n",
    "        pred_prob, pred = torch.max(F.softmax(logits.data,1), 1)\n",
    "        preds.extend(list(pred.cpu().detach().numpy()))\n",
    "        preds_prob.extend(list(pred_prob.cpu().detach().numpy()))\n",
    "        reverse_outputs = model(input_ids=reverse_ids)\n",
    "        reverse_logits = reverse_outputs[0]\n",
    "        reverse_pred_prob, reverse_pred = torch.max(F.softmax(reverse_logits.data,1), 1)\n",
    "        reverse_preds.extend(list(reverse_pred.cpu().detach().numpy()))\n",
    "        reverse_preds_prob.extend(list(reverse_pred_prob.cpu().detach().numpy()))\n",
    "\n",
    "    pred_df = pd.DataFrame({'marked_sentence':marked_sentences,'init_pred':preds,'init_pred_prob':preds_prob,'reverse_pred':reverse_preds,'reverse_pred_prob':reverse_preds_prob})\n",
    "    # map label(0, 1, 2...) to raw label(T, C, Sa...)\n",
    "    pred_df['init_pred'] = pred_df['init_pred'].replace(dict(label_df.set_index(['label'])['label_raw']))\n",
    "    pred_df['reverse_pred'] = pred_df['reverse_pred'].replace(dict(label_df.set_index(['label'])['label_raw']))\n",
    "    # judge the order of a pair of entities\n",
    "    pred_df['filter'] = pred_df.apply(lambda x:Filter(x), axis=1)\n",
    "    pred_df['pred'] = pred_df['init_pred']\n",
    "    pred_df['pred_prob'] = pred_df['init_pred_prob']\n",
    "    pred_df.loc[pred_df['filter']=='reverse_pred','pred'] = pred_df.loc[pred_df['filter']=='reverse_pred','reverse_pred']\n",
    "    pred_df.loc[pred_df['filter']=='reverse_pred','pred_prob'] = pred_df.loc[pred_df['filter']=='reverse_pred','reverse_pred_prob']\n",
    "    pred_df = pred_df.loc[pred_df['filter']!='uncorrect']\n",
    "    pred_df = marked_sentence_df.merge(pred_df,how='inner',on='marked_sentence')\n",
    "    pred_df['init_start_entity'] = pred_df['start_entity']\n",
    "    pred_df['init_start_entity_type'] = pred_df['start_entity_type']\n",
    "    pred_df.loc[pred_df['filter']=='reverse_pred','start_entity'] = pred_df.loc[pred_df['filter']=='reverse_pred','end_entity']\n",
    "    pred_df.loc[pred_df['filter']=='reverse_pred','start_entity_type'] = pred_df.loc[pred_df['filter']=='reverse_pred','end_entity_type']\n",
    "    pred_df.loc[pred_df['filter']=='reverse_pred','end_entity'] = pred_df.loc[pred_df['filter']=='reverse_pred','init_start_entity']\n",
    "    pred_df.loc[pred_df['filter']=='reverse_pred','end_entity_type'] = pred_df.loc[pred_df['filter']=='reverse_pred','init_start_entity_type']\n",
    "    pred_df.drop(['init_start_entity','init_start_entity_type'],axis=1,inplace=True)\n",
    "    pred_df.to_csv('D:\\\\IJS_MASTER\\\\SemanticWebTechnologies\\\\Covid19_Dataset\\\\data\\\\%s\\\\%s_pred.csv'%(args.prediction_path,args.task_type),index=False)\n",
    "    torch.cuda.empty_cache()\n",
    "    return\n",
    "\n",
    "Train(evalEpochs=5)\n",
    "Evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_graph(df,relation=False,repulsion=40,title='COVID-19 knowledge graph',labelShow=False):\n",
    "    entity_type_dic = dict(df.drop_duplicates(['start_entity']).set_index(['start_entity'])['start_entity_type'])\n",
    "    entity_type_dic.update(dict(df.drop_duplicates(['end_entity']).set_index(['end_entity'])['end_entity_type']))\n",
    "    color = {'Disease':'#FF7F50','Gene':'#48D1CC','Chemical':'#B3EE3A'}\n",
    "    cate =  {'Disease':0,'Gene':1,'Chemical':2}\n",
    "    categories = [{'name':'Disease','itemStyle': {'normal': {'color': color['Disease']}}},{'name':'Gene','itemStyle': {'normal': {'color': color['Gene']}}},{'name':'Chemical','itemStyle': {'normal': {'color': color['Chemical']}}}]\n",
    "    nodes = []\n",
    "    for entity in list(set(df['start_entity'])|set(df['end_entity'])):\n",
    "        nodes.append({'name': entity, 'symbolSize': max(10,np.log1p(df.loc[(df['start_entity']==entity)|(df['end_entity']==entity)].shape[0])*10//1),\n",
    "                     'category':cate[entity_type_dic[entity]]})\n",
    "    links = []\n",
    "    for i in df.index:\n",
    "        if not relation:\n",
    "            links.append({'source': df.loc[i,'start_entity'], 'target': df.loc[i,'end_entity']})\n",
    "        else:\n",
    "            links.append({'source': df.loc[i,'start_entity'], 'target': df.loc[i,'end_entity'], 'value':df.loc[i,'pred']})\n",
    "    g = (\n",
    "        Graph()\n",
    "        .add('', nodes, links,categories, repulsion=repulsion,label_opts=opts.LabelOpts(is_show=labelShow))\n",
    "        .set_global_opts(title_opts=opts.TitleOpts(title=title),legend_opts=opts.LegendOpts(orient='vertical', pos_left='2%', pos_top='40%',legend_icon='circle'))\n",
    "        .render_notebook()\n",
    "        )\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.task_type = 'chemical-disease'\n",
    "c_d_label_df,c_d_pred_df = Predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemical-disease relation theme\n",
    "c_d_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemical-disease classification results\n",
    "c_d_pred_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemical-gene relation prediction\n",
    "args.task_type = 'chemical-gene'\n",
    "c_g_label_df,c_g_pred_df = Predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemical-gene relation theme\n",
    "c_g_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemical-gene classification results\n",
    "c_g_pred_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene-disease relation prediction\n",
    "args.task_type = 'gene-disease'\n",
    "g_d_label_df,g_d_pred_df = Predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene-disease relation theme\n",
    "g_d_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene-disease classification results\n",
    "g_d_pred_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene-gene relation prediction\n",
    "args.task_type = 'gene-gene'\n",
    "g_g_label_df,g_g_pred_df = Predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene-gene relation theme\n",
    "g_g_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene-gene classification results\n",
    "g_g_pred_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene-gene relation theme\n",
    "g_g_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene-gene classification results\n",
    "g_g_pred_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemicl-COVID-19 relations\n",
    "g = Build_graph(c_d_pred_df.loc[(c_d_pred_df['start_entity']=='COVID-19')|(c_d_pred_df['end_entity']=='COVID-19')],relation=True,repulsion=800,title='chemical-COVID-19 knowledge graph',labelShow=True)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene-COVID-19 relations\n",
    "g = Build_graph(g_d_pred_df.loc[(g_d_pred_df['start_entity']=='COVID-19')|(g_d_pred_df['end_entity']=='COVID-19')],relation=True,repulsion=60,title='gene-COVID-19 knowledge graph',labelShow=False)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene-COVID-19 relations\n",
    "g = Build_graph(marked_sentence_df.loc[(marked_sentence_df['start_entity']=='COVID-19')&(marked_sentence_df['end_entity_type']=='Disease')|(marked_sentence_df['start_entity_type']=='Disease')&(marked_sentence_df['end_entity']=='COVID-19')],relation=False,repulsion=60,title='disease-COVID-19 topology graph',labelShow=False)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all relation prediction and save results\n",
    "cols = ['start_entity','end_entity','start_entity_type','end_entity_type','marked_sentence','pred','pred_prob']\n",
    "relation_df = pd.concat([c_d_pred_df[cols],c_g_pred_df[cols],g_d_pred_df[cols],g_g_pred_df[cols]]).append(marked_sentence_df.loc[(marked_sentence_df['start_entity_type'].isin(['Chemical','Disease'])&(marked_sentence_df['start_entity_type']==marked_sentence_df['end_entity_type']))]).reset_index(drop=True)\n",
    "relation_df.loc[(relation_df['pred'].isna())&(relation_df['start_entity_type']=='Chemical'),'pred'] = 'CC'\n",
    "relation_df.loc[(relation_df['pred'].isna())&(relation_df['start_entity_type']=='Disease'),'pred'] = 'DD'\n",
    "relation_df = relation_df[cols]\n",
    "relation_df.to_csv('relation.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample of knowledge graph\n",
    "g = Build_graph(relation_df.sample(1000),relation=True,repulsion=15,title='subsample of COVID-19 knowledge graph',labelShow=False)\n",
    "g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
